
\begin{comment}
	\jw{Introduce loop summarization using rational vector addition systems with resets \\
	- What are qvasr? What are qvasr abstractions? what are least upper bounds on abstractions? \\
	- start with qvasr on example that does not need abstraction $\rightarrow$ no relations between variables \\
	- move on to example with relations between variables; show simulation matrix and imaging \\
	- abstractions are an overapproximation \\
	- imprecise because of ignorance of assumptions $\rightarrow$ transfer to next chapter \\
	- usage of running example which is turned to qvasr abstraction \\
	\vspace{1cm}
	20 pages}
\end{comment}

This chapter will firstly give an overview of the challenges program loops introduce, then we will define our understanding of the loop summarization technique based on rational vector addition systems with resets (\qvasr), which will then be extended to \qvasr-abstractions, and lastly we introduce rational vector addition systems with resets and states (\qvasrs). \\ \par
A program loop, created by, for example, a \texttt{while} statement, can introduce up to infinitely many program traces. Let us, for instance, assume we have a non deterministic loop:
\begin{equation*}
	\texttt{while (*); x:=2*x}
\end{equation*}
and an error location outside of the loop asserting \texttt{x\%2==0}. To check safety we would have to prove, in the worst case, infinitely many program traces as infeasible because there are theoretically infinitely many traces through the loop.
.\begin{center}
	\begin{minipage}[b]{0.4\linewidth}
		\begin{figure}[H]
			\centering
			\input{fig/lst_code_mod.tex}
			\caption{Program $P_1$ with nondeterministically terminating loop.}
			\label{codeExMotAss}
		\end{figure}
	\end{minipage}
	\hfill
	\begin{minipage}[b]{0.59\linewidth}
		\begin{figure}[H]
			\centering
			\input{fig/fig_cfg_mod.tex}
			\caption{Control-flow graph $G_{P_1}$ for program $P_1$.}
			\label{cfgExMotAss}
		\end{figure}
	\end{minipage}
\end{center}
Instead, we can compute a loop summarization that characterizes changes to variables as a first-order logic formula. Loop summaries are not guaranteed to be precise, meaning they can over- or underapproximate the loop's behavior. Feasible error traces, found using underapproximative loop summaries, are guaranteed to be feasible. But due to the underapproximate nature of the summaries they can miss other feasible counterexample as they model only a subset of the actual loop behavior \cite{DBLP:journals/fmsd/KroeningLW15}. Loop summaries that overapproximate the loop's behaviour, on the other hand, form a superset of the actual loop behavior, resulting in possible spurious feasible error traces. The quality of overapproximative loop summaries depend on the degree of overapproximation of the actual loop behavior.
Kincaid et al. \cite{DBLP:conf/cav/SilvermanK19} devised an overapproximative loop summarization method that guarantees a certain degree of precision by utilizing rational vector addition systems with resets. In the following we present our adaption of that summarization technique.
\subsection{\qvasr}
To summarize a loop, we make use vector addition systems. Vector additions systems are a class of infinite-state transition systems.

\begin{mydef}[Transition System]
	A transition system \transSys{} is a tuple, consisting of a finite or infinite set of states $S$ and a transition relation $\rightarrow \subseteq S \times S$.
\end{mydef}

A concretization of a transition system is a vector addition system that is defined over rational values.

\begin{mydef}[Rational Vector Addition System]
	Given two vectors $\vec{u}$, and $\vec{v}$ consisting of $d$ rational numbers, a rational vector addition system $V$ of dimension $d$ is a finite set $V \subseteq \mathbb{Q}^d$ of transformers. A transformer $\vec{a}$ is a vector of length $d$, called addition vector, containing rational numbers. Rational vector addition systems define a transition system \transSys{V}, with state space $S_V = \mathbb{Q}$ and transition relation $\vec{u} \rightarrow_V \vec{v}$ if and only if $\vec{v} = \vec{u} + \vec{a}$ for some $\vec{a} \in V$. 
\end{mydef}
We want to model changes to variables in a loop using rational vector addition systems, however, additions alone do not cover all possible transitions. A variable can be \textsl{reset} to an arbitrary constant. For example, the transition \st{x:=0} sets variable \texttt{x} to zero no matter what value $x$ had before the transition. We extend rational vector addition systems to rational vector addition systems with resets (\qvasr).

\begin{mydef}[Rational Vector Addition Systems with Resets]
		Given two vectors $\vec{u}$, and $\vec{v}$ consisting of $d$ rational numbers, a rational vector addition system with resets (\qvasr) $V$ of dimension $d$ is a rational vector addition system $V \subseteq \{0, 1\}^d \times \mathbb{Q}^d$, where each transformer consists of a addition vector $\vec{a} \subseteq \mathbb{Q}^d$ and a binary reset vector $\vec{r} \subseteq \{0, 1\}^d$. A \qvasr defines a transition system \transSys{V}, with state space $S_V = \mathbb{Q}$ and transition relation $\vec{u} \rightarrow_V \vec{v}$ if and only if $\vec{v} = \vec{r} * \vec{u} + \vec{a}$ for some $(\vec{r}, \vec{a}) \in V$, with $*$ being the Hadamard product.
\end{mydef}
We see, that there are three distinct changes to variables modelled in \qvasr: A variable is incremented, for example \st{x:=x+1}, a variable is reset to zero, as in \st{x:=0}, or a variable is reset and then incremented to a constant, \st{x:=3}. \par

A \qvasr can be used to represent an overapproximation of a given transition formula. A transition formula $\trf_1$ over variables $\vec{x} = x_1, \ldots, x_n$ and $\vec{x}' = x_1', \ldots, x_n'$ designate the program state before and after the transition, $n$ is called the dimension of the formula. Transition formula $\trf_1$ defines a transition system $(S_{\trf_1}, \rightarrow_{\trf_1})$, where $S_{\trf_1}$ is defined over the domains of $\vec{x}$, whereas two program states $\sigma_1$, $\sigma_2$ can transition $\sigma_1 \rightarrow_{\trf_1} \sigma_2$ if and only if the variable valuations of $\sigma_1$ as $\vec{x}$ and valuations of $\sigma_2$ as $\vec{x}'$ is valid. \\ \par
Figure \ref{codeWithAss} depicts a program containing a \texttt{while} loop from lines 4 - 12 for which we want to compute a loop summary using \qvasr. \par
To get a loop summary, approximating the entire loop, we need to compute a \qvasr for every path through the loop. In this example there are two paths created by the \texttt{if else} statement.
Beginning with the \texttt{else} branch, from line 9 to 12, we extract the transition formula:
\begin{equation*}
	G= \ (x \leq 20 \land\ x > 10 \land x' = x + 2 \land y' = y - 3)
\end{equation*}
We see, that variable $x$ is not reset but incremented by 2 and variable $y$ is not reset and decremented by 3 variable $z$ does not appear in this branch, it consequently stays the same, meaning it is not reset and incremented by 0.
Knowing this, we get reset vector: $
\vec{r}_G = \  
\begin{bmatrix}
	1 \\
	1 \\
	1
\end{bmatrix}
$
and addition vector $
\vec{a}_G = \ 
\begin{bmatrix}
	2 \\
	-3 \\
	0
\end{bmatrix}$ \\
$G$ can therefore be modeled by the \qvasr
$V_G = 
\begin{Bmatrix}
	\begin{pmatrix}
		\begin{bmatrix}
			1 \\
			1 \\
			1
		\end{bmatrix},
		\begin{bmatrix}
			2 \\
			-3 \\
			0
		\end{bmatrix}
	\end{pmatrix}
\end{Bmatrix}
$ \par \vspace{2pt}
We will introduce the following, more intuitive notation that shows relations between variables more clearly:
\begin{equation*}
	V_G = 
	\begin{Bmatrix}
		\begin{bmatrix}
			x' = x + 2 \\
			y' = y - 3 \\
			z' = z
		\end{bmatrix}
	\end{Bmatrix}
\end{equation*}
\subsection{\qvasr Summarization}
\qvasr can only model the aforementioned three transitions: increment, reset, and reset and increment. Increments, and resets and increments, however, are tied to constant variable changes. Updates that reference, for example, other variables, cannot be modeled as a \qvasr. When we look at the example program \ref{cfg:P:Ass}, we can see that in the \texttt{if} branch there are increments that reference other variables, such as \st{z:=x} and \st{x:=x+y}. \\

\subsubsection{\qvasr-Abstraction}
We extract the transition formula $H$ of the if branch:
\begin{equation*}
	H= \ (x \leq 10 \land x' = x + y\ \land\ y' = y + 1 \land z' = x)
\end{equation*}
It is possible to overapproximate $H$ using a \qvasr using linear simulations.

\begin{mydef}[Linear Simulation]
	Given two transition systems $T_1 = (\valuations^n, \rightarrow_1)$ and $T_2 = (\valuations^m, \rightarrow_2)$, operating over the vector space containing rational numbers, a linear simulation from $T_1$ to $T_2$ is a linear transformation $S: \valuations^{m \times n}$ such that for all vectors $\vec{u}$, $\vec{v} \in \valuations^n$ with $\vec{u} \rightarrow_1 \vec{v}$, we have $S\vec{u} \rightarrow_2 S\vec{v}$. We denote the linear simulation from $T_1$ to $T_2$ as $T_1 \vdash_S T_2$
\end{mydef}
We want to synthesize a \qvasr $V_H$ and linear simulation $S_H$, such that $H \vdash_S V$. The tuple $(S_H, V_H)$ is called a \qvasr-abstraction.
\begin{mydef}[\qvasr-Abstraction]
	Given a transition formula \trf of dimension $n$ and a \qvasr $V$ of dimension $m$, a linear simulation from \trf to $V$ is a linear transformation matrix: 
	$S = 
	\begin{bmatrix}
		s_{1 ,1} & \ldots & s_{1, n} \\
		\vdots & \ddots & \vdots \\
		s_{m ,1} & \ldots & s_{m, n} \\
	\end{bmatrix}$ 
	such that for all transitions $\vec{x} \rightarrow_\trf \vec{x}'$ we have $S\vec{x} \rightarrow_V S\vec{x}'$. Meaning, every transition $\vec{x} \rightarrow_\trf \vec{x}'$ can be represented in $V$ by a matrix multiplication of $S$ and $\vec{x}$ and $\vec{x}'$. We call $n$ the abstraction's concrete, and $m$ the abstraction's abstract dimension. 
\end{mydef}
To abstract a transition formula $\trf$ with $n$ variables $\vec{x} = x_1, \ldots, x_n$, we need to calculate both the linear transformation matrix $S$ and the \qvasr $V$. We know that a \qvasr consists of pairs of transformers, which contain reset and addition vectors. Using the formula $S \vec{u} \rightarrow_V S\vec{u}$, we get a transition in $V$ as $S\vec{x}' = \vec{r}*S\vec{x} + \vec{a}$. \\ To get variables that are reset, we consider $\vec{r}$ as the zero vector $\vec{0}$, and get the formula $S\vec{x}' = \vec{a}$ which forms a linear set of equations that models the set of resets:
\begin{equation*}
	Res_\trf = \left\{ (\sn, a)\ |\ \sn \pn = a \right\}	
\end{equation*}
For the set of additions, we consider $\vec{r}$ as the constant one vector $\vec{1}$, and get formula $S\vec{x}' = S\vec{x} + \vec{a}$ which forms the set of additions as:
\begin{equation*}
	Inc_\trf = \left\{(\sn, a)\ |\ \sn \pn = \sn \upn + a\right\}	
\end{equation*}
\begin{comment}
	\begin{equation*}
	Res_H = \left\{ (\s, a) | H \models \s \cdot \p = a \right\}	
	\end{equation*}
	
	\begin{equation*}
	Inc_H = \left\{(\s, a) | H \models \s \cdot \p = \s \cdot \up + a\right\}	
	\end{equation*}
\end{comment}
By solving the following equations for $s_1, \ldots, s_n$: \\
\begin{align*}
	Res_\trf &= \sn \pn = a \\
 			&= s_1x_1 + \ldots s_nx_n = a
\end{align*}

\begin{align*}
	Inc_\trf &= \sn \pn = \sn \upn + a  \\ \vspace{0.5cm}
			 &= s_1x_1' + \ldots s_nx_n' = s_1x_1 + \ldots + s_nx_n + a
\end{align*}
We get two sets that represent linear combinations of variables that are reset and incremented across \trf. We observe that the two form a vector space. These spaces can be represented using vector space basis vectors, meaning, we have to compute a basis. Assume we have basis for the set of resets:
$Res_\trf = \{(\vec{s}_1, a_1), \ldots, (\vec{s}_m, a_m)\}$ and basis for the set of additions as: $Inc_\trf = \{(\vec{s}_{m+1}, a_{m+1}), \ldots, (\vec{s}_d, a_d)\}$. \\ We construct the \qvasr-abstraction $(S, V)$ as:
\begin{center}
\begin{minipage}{0.3\linewidth}
	\begin{equation*}
		S = \begin{bmatrix} \vec{s_1} & \ldots & \vec{s_d} \end{bmatrix}
	\end{equation*}
\end{minipage}
\begin{minipage}{0.3\linewidth}
	\begin{equation*}
		\vec{r} = [ \underbrace{0 \ldots 0}_{m\text{ times}} \overbrace{1 \ldots 1}^{d - m \text{ times}} ]
	\end{equation*}
\end{minipage}
\begin{minipage}{0.3\linewidth}
	\begin{equation*}
		\vec{a} = \begin{bmatrix} a_1 \\ \vdots \\ a_d \end{bmatrix}
	\end{equation*}
\end{minipage}
\end{center}

For transition formula $H$, we need to calculate the matrix $S_H$ and the \qvasr $V_H$.
We use the assignments to variables: $x' = x + y, \ y'= y + 1\ z' = x$ , found in $H$, to solve the following equations for $s_1, s_2,  s_3$:
\begin{align*}
	Res_H:& \hspace*{1cm} s_1(x + y) + s_2(y + 1) + s_3x = a \\
	Inc_H:& \hspace*{1cm} s_1(x + y) + s_2(y + 1) + s_3x = s_1x + s_2y + s_3z + a
\end{align*}
resulting in the following sets:
\vspace*{-0.5em}
\begin{center}
	\begin{minipage}{0.5\linewidth}
		\begin{equation*}
			Res_H = \left\{ (\begin{bmatrix} -a & a & a \end{bmatrix}, a) \right\}\
		\end{equation*}
	\end{minipage}
	\begin{minipage}{0.4\linewidth}
		\begin{equation*}
			Inc_H = \left\{ (\begin{bmatrix} 0 & a & 0 \end{bmatrix}, a) \right\}\ 
		\end{equation*}
	\end{minipage}
\end{center}
$Res_H$ and $Inc_H$ form a vector space, and, because we want to construct a linear combination of reset and incremented variables along $H$, we need to compute a basis for each space:
\vspace*{-1em}
\begin{center}
	\begin{minipage}{0.5\linewidth}
		\begin{equation*}
			Res_H = \{(
			\NiceMatrixOptions{code-for-first-row=\scriptstyle}
			\begin{bNiceMatrix}[first-row=1]
				x & y & z \\
				-1 & 1 & 1 
			\end{bNiceMatrix}, 1)\}
		\end{equation*}
	\end{minipage}
	\begin{minipage}{0.4\linewidth}
		\begin{equation*}
			Inc_H = \{(
			\NiceMatrixOptions{code-for-first-row=\scriptstyle}
			\begin{bNiceMatrix}[first-row=1] 
				x & y & z \\
				0 & 1 & 0 
			\end{bNiceMatrix}, 1)\}
		\end{equation*}
	\end{minipage}
\end{center}
Each column of the basis corresponds to a variable in the formula such that we can derive relations between variables. From the reset base we can deduce that the sum $-x + y + z$ is reset and incremented by $1$, meaning that after each transition of $H$ we know that $-x + y + z = 1$ holds. From the basis of additions we derive that $y$ is not reset and incremented by $1$. To form the linear transformation matrix $S_H$ we combine these rows to one coherent matrix. We see that the basis of resets and additions contain only one vector each, resulting in only one reset addition pair for $V_H$. As we have seen $-x + y + z$ is reset and $y$ is not. We get reset vector $\vec{r} = \begin{bmatrix} 0 \\ 1 \end{bmatrix}$ and because $-x + y + z$ is incremented by $1$, same as $y$, we get addition vector $\vec{a} = \begin{bmatrix} 1 \\ 1 \end{bmatrix}$. Resulting in the \qvasr-abstraction depicted in figure \ref{vasr  H}.
\vspace*{-2em}
\begin{figure}[H]
	\begin{center}
		\begin{minipage}{0.3\linewidth}
			\begin{equation*}
				S_H = \begin{bmatrix} -1 & 1 & 1 \\ 0 & 1 & 0 \end{bmatrix}
			\end{equation*}
		\end{minipage}
		\begin{minipage}{0.6\linewidth}
			\begin{equation*}
				V_H = \begin{Bmatrix} \begin{bmatrix} -x' + y' + z' = 1\\ y' = y + 1 \end{bmatrix} \end{Bmatrix}
			\end{equation*}
		\end{minipage}
		\caption{\qvasr-abstraction of transition formula $H$.}
		\label{vasr H}
	\end{center}
\end{figure}
\vspace*{-2em}
Given a transition formula \trf with variables $\vec{x} = x_1, \ldots, x_n$ and $\vec{x}' = x_1', \ldots, x_n'$ a \qvasr-abstraction $(S, V)$ that simulates \trf, with transformer $(\vec{r}_1, \vec{a}_1), \ldots, (\vec{r}_m, \vec{a}_m) \in V$ where each $\vec{r}_i, \vec{a}_i$ has $d$ entries, we compute a transition formula overapproximating one transition of \trf by constructing the following disjunction:
\begin{figure*}[H]
	\begin{equation*}
		\bigvee\limits_{i=1}^m \bigwedge\limits_{j=0}^d S\vec{x}' = S\vec{x} * \vec{r}_j + \vec{a}_j
	\end{equation*}
	\label{vasrTrans}
	\caption{\qvasr-abstraction formula.}
\end{figure*}

The \qvasr-abstractions are overapproximations because they do not model single program variable transitions but, rather, transitions of relations of variables. These relations lead to an overhead of actual program behaviour, as a transition is possible, as long as the transition formula, described by the \qvasr-abstraction, holds. \\
For example, the \qvasr-abstraction  $(S_H, V_H)$ of $H$ is an overapproximation, because, for instance, the transition: $\begin{bNiceMatrix}[first-col=1]  x & 1\\ y & 2 \\ z & 3 \end{bNiceMatrix} \rightarrow \begin{bNiceMatrix}[last-col]  -20 & x'\\ 3 & y' \\ 18 & z' \end{bNiceMatrix}$ is possible because $-x' + y' + z' = 1$ and $y' = y + 1$ hold. In $H$ this transition is not possible, because of $z' = x$ and $x' = x + y$. \\ \par
For transition formulas with constant increments, such as $G$, the identity matrix $I$ is used as simulation matrix. These \qvasr-abstractions are precise. \par

\subsubsection{\qvasr-Abstraction Join}
The changes to program states by the loop in $P$ can be represented by the transition formula: 
\begin{equation*}
	L = x \leq 20 \land (H \lor G)
\end{equation*}
With $x \leq 20$ being the loop guard. We have already computed \qvasr-abstractions for $G$ and $H$. These, however, only model the effect on variables in their respective branch of the \texttt{if else} statement. To get the approximation of the whole loop's behavior we need to compute the \qvasr-abstraction $(\tilde{S}_L, \tilde{V}_L)$ that simulates $L$. \\ \par We impose a partial order to model simulations between \qvasr-abstractions.
\begin{mydef}[\qvasr-Abstraction Preorder]
	Given two \qvasr-abstractions  \qvAbstr{1} and \qvAbstr{2}, with abstract dimensions $e$ and $d$ respectively, we define the preorder \\ of \qvasr-abstractions as \qvAbstr{1} $\preceq$ \qvAbstr{2} if and only if there exists a linear transformation $T \in \valuations^{e \times d}$ where $V_1 \vdash_S V_2$ and $TS_1 = S_2$
\end{mydef}
The \qvasr-abstraction $(\tilde{S}_L, \tilde{V}_L)$ has to simulate both $(S_G, V_G)$ and $(S_H, V_H)$, consequently $(S_G, V_G) \preceq (\tilde{S}, \tilde{V})$ and $(S_H, V_H) \preceq (\tilde{S}_L, \tilde{V}_L)$ has to hold. Additionally, we want a precise as possible \qvasr-abstraction, we have to define $(\tilde{S}_L, \tilde{V}_L)$ as the least upper bound with regard to the preorder. The \qvasr-abstraction that represents the least upper bound is called the \textsl{best} \qvasr-abstraction. \\ \par

Given two \qvasr-abstractions $(S_1, V_1)$ and $(S_2, V_2)$ to compute a best \\ \qvasr-abstraction $(\tilde{S}, \tilde{V})$ such that $(S_1, V_1) \preceq (\tilde{S}, \tilde{V})$ and $(S_2, V_2) \preceq (\tilde{S}, \tilde{V})$ we use the definition of the preorder, to describe that if $(\tilde{S}, \tilde{V})$ is an upper bound of $(S_1, V_1)$ and $(S_2, V_2)$ then there exists matrices $T_1$ and $T_2$ such that $T_1S_1 = \tilde{S} = T_2S_2$ with $V_1 \vdash_{T_1} \tilde{V}$ and $V_2 \vdash_{T_2} \tilde{V}$. To compute the unknown $T_1$ and $T_2$ we convert the equation $T_1S_1 = \tilde{S} = T_2S_2$ to $T_1S_1 = T_2S_2$. \\
We have $T_1S_1 = T_2S_2$ if and only if, each pair of rows $(\vec{t}_{1i}\vec{t}_{2i})$ of $T_1$ and $T_2$, is part of the set $\{ (t_1t_2)\ |\  \vec{t}_1S_1 = \vec{t}_2S_2\}$. Observe that this set forms a vector space, a basis for this space form our $(\vec{t}_{1i}\vec{t}_{2i})$. \\ \par
For example, assume we are given simulation matrices: 
\begin{align*}
	S_G = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\0 & 0 & 1 \end{bmatrix} \hspace{1cm}
	S_H = \begin{bmatrix} -1 & 1 & 1 \\ 0 & 1 & 0 \end{bmatrix}
\end{align*}
 from before, to compute $\tilde{S}_H$, we need to compute $T_G$ and $T_H$ such that $T_GS_G = \tilde{S}_L = T_HS_H$. We define the set $\{ (\vec{t}_G\vec{t}_H)\ |\  \vec{t}_GS_G = \vec{t}_GS_H\}$ for which we have to solve for $\vec{t}_G$ and $\vec{t}_H$. Because $S_G$ has abstract dimension three and $S_H$ has abstract dimension two, we know that $\vec{t}_G$ is a vector of dimension three and $\vec{t}_H$ of dimension two. We get the following set:
\begin{align*}
	\{ (\begin{bmatrix} t_{G1} & t_{G2} & t_{G3} & t_{H1} & t_{H2} \end{bmatrix})\ |\  \begin{bmatrix} t_{G1} & t_{G2} & t_{G3}\end{bmatrix}S_G = \begin{bmatrix} t_{H1} & t_{H2} \end{bmatrix}S_H\}
\end{align*}
From which we extract the equation:
\begin{align*}
	 \begin{bmatrix} t_{G1} & t_{G2} & t_{G3}\end{bmatrix}\begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\0 & 0 & 1 \end{bmatrix} &= \begin{bmatrix} t_{H1} & t_{H2} \end{bmatrix}\begin{bmatrix} -1 & 1 & 1 \\ 0 & 1 & 0 \end{bmatrix} \\
\end{align*}
Solving the equation yields: 
\begin{align*}
		 \begin{bNiceMatrix} t_{G1} \\ t_{G2} \\ t_{G3} \end{bNiceMatrix} &= \begin{bNiceMatrix} -t_{H1} \\ t_{H1} + t_{H2} \\ t_{H1} \end{bNiceMatrix}
\end{align*}
We get the vector space $\{ \begin{bNiceMatrix} -t_{H1} & t_{H1} + t_{H2} & t_{H1}&  t_{H1} & t_{H2} \end{bNiceMatrix}  \}$, which has vector space basis $\{ \begin{bNiceMatrix} -1 & 1 & 1 &  1 & 0 \end{bNiceMatrix}, \begin{bNiceMatrix} 0 & 1 & 0 & 0 & 1 \end{bNiceMatrix} \}$. Combining these basis vectors we get the following matrices: 
\begin{align*}
	T_GT_H = \begin{bmatrix}  -1 & 1 & 1 & 1 & 0 \\ 0 & 1 & 0 & 0 & 1\end{bmatrix}\hspace{1cm} T_G = \begin{bmatrix}  -1 & 1 & 1 \\ 0 & 1 & 0\end{bmatrix} \hspace{1cm} T_H = \begin{bmatrix}  1 & 0 \\  0 & 1\end{bmatrix}
\end{align*}
Now we insert $T_G$ and $T_H$ into the formula $T_GS_G = \tilde{S}_L = T_HS_H$:
\begin{align*}
	\begin{bmatrix}  -1 & 1 & 1 \\ 0 & 1 & 0\end{bmatrix} \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\0 & 0 & 1 \end{bmatrix} = \begin{bmatrix}  -1 & 1 & 1 \\ 0 & 1 & 0\end{bmatrix} = \begin{bmatrix}  1 & 0 \\  0 & 1\end{bmatrix}\begin{bmatrix}  -1 & 1 & 1 \\ 0 & 1 & 0\end{bmatrix}
\end{align*}
to get $\tilde{S}_L = \begin{bmatrix}  -1 & 1 & 1 \\ 0 & 1 & 0\end{bmatrix}$ \\ \par

Knowing how to compute a simulation matrix, we continue with the calculation of the \qvasr. Firstly, we need to introduce \qvasr coherence.

\begin{mydef}[\qvasr Coherence Classes]
	Given a \qvasr $V$ of dimension $d$, we say dimensions $i, j \in \{1, \ldots, d\}$ are coherent, if for all transformer $(\vec{r}, \vec{a}) \in V$, $r_i = r_j$ holds. This means that if a transition in $V$ resets $i$ it also resets $j$ and vice versa. We denote coherence as $i \equiv_V j$ and observe that coherence forms an equivalence relation on dimensions $\{1, \ldots, d\}$. We call the equivalence classes coherence classes of $V$.
\end{mydef}
Given a matrix $T \in \mathbb{Q}^{e \times d}$ and a \qvasr $V$ of dimension $d$ with $k$ coherence classes $C = \{c_1, \ldots, c_k\}$, we say that $T$ is coherent to $V$ if and only if each of its rows have non-zero values only in the dimensions corresponding to a single coherence class of $c_i \in C$. \\ \par
Let $V$ be a \qvasr with transition relation $\rightarrow_V$, let matrix  $T \in \mathbb{Q}^{e \times d}$ be a coherent to $V$ matrix that has no rows consisting entirely of zeroes, there is a \qvasr $image(V, T)$ of dimension $e$, that has transition relation $\rightarrow_{image(V, T)} = \{(T\vec{u}, T\vec{v})\ |\ (\vec{u}, \vec{v}) \in\rightarrow_V \}$ and is defined as $image(V, T) = \{(T\boxtimes\vec{r}, T\vec{a})\}$ for every transformer $(\vec{r}, \vec{a}) \in V$. Where $T\boxtimes\vec{r}$ denotes the translation of reset vector $\vec{r}$ along $T$, and is defined as $(T\boxtimes\vec{r})_i = r_j$ where $j$ is an arbitrary choice of dimensions for which $T_{ij}$ is non-zero. \\ \par
\begin{mydef}[\qvasr-Image]
Given two \qvasr-abstractions $(S_1, V_1)$ and $(S_2, V_2)$ and matrices $\tilde{S}$, $T_1$, and $T_2$ where $T_1S_1 = \tilde{S} = T_2S_2$, we define the \qvasr $\tilde{V} = image(V_1, T_1) \cup image(V_2, T_2)$ as the \qvasr-image of $V_1$ and $V_2$.
\end{mydef}
The tuple $(\tilde{S}, \tilde{V})$ is the best \qvasr-Abstraction of $(S_1, V_1)$ and $(S_2, V_2)$. \\ \par
We will demonstrate the image calculation to compute \qvasr $\tilde{V}_L$ using:
\begin{align*}
	V_G = 
	\begin{Bmatrix}
		\begin{pmatrix}
			\begin{bmatrix}
				1 \\
				1 \\
				1
			\end{bmatrix},
			\begin{bmatrix}
				2 \\
				-3 \\
				0
			\end{bmatrix}
		\end{pmatrix}
	\end{Bmatrix} \hspace{1cm}
	V_H =\begin{Bmatrix}
		\begin{pmatrix}
			\begin{bmatrix}
				0 \\
				1
			\end{bmatrix},
			\begin{bmatrix}
				1 \\
				1
			\end{bmatrix}
		\end{pmatrix}
	\end{Bmatrix}
\end{align*}

and matrices
\begin{align*}
	T_G = \begin{bmatrix}  -1 & 1 & 1 \\ 0 & 1 & 0\end{bmatrix} \hspace{1cm} T_H = \begin{bmatrix}  1 & 0 \\  0 & 1\end{bmatrix}
\end{align*}

We define $\tilde{V}_L = image(V_G, T_G) \cup image(V_H, T_H)$, and begin by computing $image(V_G, T_G)$:
\begin{align*}
	image(V_G, T_G) = \{(T_G\boxtimes\vec{r}, T\vec{a})\} \text{ for every transformer } (\vec{r}, \vec{a}) \in V_G
\end{align*}
There is only one reset vector $\vec{r}_1 = \begin{bmatrix}1 \\ 1 \end{bmatrix}$ in $V_G$, such that:
\begin{align*}
	T_G\boxtimes\vec{r}_1 = \begin{bmatrix}  -1 & 1 & 1 \\ 0 & 1 & 0\end{bmatrix} \boxtimes \begin{bmatrix} 1 \\ 1 \\ 1\end{bmatrix} = \begin{bmatrix}  1 \\ 1\end{bmatrix}
\end{align*}
Where $(T_G\boxtimes\vec{r})_1 = r_1 = 1$, because $T_{11}$ is non zero, $(T_G\boxtimes\vec{r}_1)_2 = r_2 = 1$ for the same reason, and, as there is no row 3 in $T$, we stop. \\ \par
There is only one addition vector $\vec{a}_1 =  \begin{bmatrix}2 \\ -3 \\ 0\end{bmatrix}$ in $V_G$, such that:
\begin{align*}
	T_G\vec{a}_1 = \begin{bmatrix}  -1 & 1 & 1 \\ 0 & 1 & 0\end{bmatrix} \begin{bmatrix} 2 \\ -3 \\ 0\end{bmatrix} = \begin{bmatrix} -5 \\ -3 \end{bmatrix}
\end{align*}
Resulting in the \qvasr:
\begin{align*}
	image(V_G, T_G) = 
	\begin{Bmatrix}
		\begin{pmatrix}
			\begin{bmatrix}
				1 \\
				1 
			\end{bmatrix},
			\begin{bmatrix}
				-5 \\
				-3 
			\end{bmatrix}
		\end{pmatrix}
	\end{Bmatrix}
\end{align*} \par
We repeat this procedure for $image(V_H, T_H)$, which results in the \qvasr:
\begin{align*}
	image(V_H, T_H) = 
	\begin{Bmatrix}
		\begin{pmatrix}
			\begin{bmatrix}
				0 \\
				1 
			\end{bmatrix},
			\begin{bmatrix}
				1 \\
				1 
			\end{bmatrix}
		\end{pmatrix}
	\end{Bmatrix}
\end{align*}  	
Now, we can join the two \qvasr to get $\tilde{V}_L$:
\begin{align*}
		\tilde{V}_L = image(V_G, T_G) \cup image(V_H, T_H) = 
	\begin{Bmatrix}
		\begin{pmatrix}
			\begin{bmatrix}
				1 \\
				1 
			\end{bmatrix},
			\begin{bmatrix}
				-5 \\
				-3 
			\end{bmatrix}
		\end{pmatrix}, 
		\begin{pmatrix}
			\begin{bmatrix}
				0 \\
				1 
			\end{bmatrix},
			\begin{bmatrix}
				1 \\
				1 
			\end{bmatrix}
		\end{pmatrix}
	\end{Bmatrix}
\end{align*}
Combining $S_L$ and $V_L$, we get the final best \qvasr-abstraction of the loop $(\tilde{S}_L, \tilde{V}_L)$ as seen in Figure \ref{vasr}.
\begin{center}
	\begin{figure}[H]
		\input{fig/matrix_ex_p0.tex}
		\caption{Best \qvasr-abstraction of the transition formula $L$.}
		\label{vasr}
	\end{figure}
\end{center}
Given two \qvasr-abstractions $(S_1, V_1)$, and $(S_2, V_2)$, the computation of a best \qvasr-abstraction $(\tilde{S}, \tilde{V})$ with $(S_1, V_1) \preceq (\tilde{S}, \tilde{V})$ and  $(S_1, V_1) \preceq (\tilde{S}, \tilde{V})$ is called a \qvasr-abstraction \textsl{join}.

\subsubsection{\qvasr Loop Summary}
A \qvasr-abstraction only models one iteration of a transition formula, loops, however, are often repeated, such that we need to construct a formula that models every possible iteration. \\ \par
Given a \qvasr-abstraction $(S, V)$ that approximates a transition formula $\trf$ that is defined over variables $\vec{x} = x_1, \ldots, x_n$,  that consists of $l$ transformer $(\vec{r}^{\,i}, \vec{a}^{\,i}) \in V$, with abstract dimension $m$, meaning that $S$, $\vec{r}^{\, i}$, and $\vec{a}^{\, i}$ have $m$ rows, and concrete dimension $n$, meaning $S$ has $n$ columns, to construct a formula, we firstly introduce new variables for each transformer $k^1, \ldots, k^n$, these variables represent how often each transformer was used. We iterate through every dimension $d \in 1, \ldots, m$, and construct the relations: $S_d\vec{x}'$ and check each transformer's $d$-th entry: $(r_d^i, a_d^i)$ \\
As we know the relation is either reset, meaning $r_d^i = 0$, incremented by amount $y$, meaning $r_d^i = 1$ and $a_d^i = y$, or reset and incremented to amount $y$, by $r_d^i = 0$ and $a_d^i = y$. Now, when we look at multiple iterations and multiple transformers, these three changes can occur arbitrarily. We need to construct a disjunction for each dimension covering these cases, we present the following approach.
We start by constructing an empty set of disjuncts $D_d$, then iterate through every transformer:
\begin{itemize}
	\item If transformer $i$ resets dimension $d$, i.e. $r_d^i = 0$, construct new disjunct $S_d\vec{x}' = 0$
	\item If transformer $i$ increments dimension $d$ by amount $y$, i.e. $r_d^i = 1$ and $a_d^i = y$, construct formula $S_d\vec{x}' = S_d\vec{x}\ +\ k^ia_d^i$, if there is already a formula covering increments:  $S_d\vec{x}\ +\ k^ja_d^j\ +\ \ldots\ +\ k^ga_d^g$ add $+\ k^ia_d^i$ to it. There is only one disjunct representing increments.
	\item If transformer $i$ resets dimension $d$ and increments it to amount $y$, i.e. $r_d^i = 0$ and $a_d^i = y$, construct new disjunct $S_d\vec{x}' = y$
\end{itemize}
When every transformer has been processed construct a disjunction using the disjuncts sets $D_j$ generated above. We then create a conjunction over all dimensions consisting of the disjunctions of all transformer, existentially quantify each $k$, and add the disjunct $\vec{x}' = \vec{x}$ representing the case that the transition formula is not used.

\begin{equation*}
	\exists k_1, \ldots, k_n.\ \vec{x}' = \vec{x} \lor \bigwedge_{i=1}^{m} \bigvee_{j=1}^l D_j 
\end{equation*}
This formula is now a loop summary. \\
To illustrate the construction of a loop summary, we are again given $(\tilde{S}_L, \tilde{V}_L)$ as seen in Figure \ref{nonabbridged}.
\begin{figure}[H]
	\centering
	\input{fig/fig_ex_nonabbridged.tex}
	\caption{Best \qvasr-abstraction of the transition formula $L$ using the non-abridged notation.}
	\label{nonabbridged}
\end{figure}

 With $\tilde{V}$ consisting of two transformers
\begin{align*}
	(\vec{r}^{\, 1}, \vec{a}^{\, 1}) = 		
	\begin{pmatrix}
		\begin{bmatrix}
			1 \\
			1 
		\end{bmatrix},
		\begin{bmatrix}
			-5 \\
			-3 
		\end{bmatrix}
	\end{pmatrix} \hspace*{1cm}
	(\vec{r}^{\, 2}, \vec{a}^{\, 2}) = 		
	\begin{pmatrix}
		\begin{bmatrix}
			0 \\
			1 
		\end{bmatrix},
		\begin{bmatrix}
			1 \\
			1 
		\end{bmatrix}
	\end{pmatrix}
\end{align*}

We begin the procedure by introducing fresh variables $k_1$ and $k_2$ representing iterations of each transformer. We the construction of the disjunction for dimension 1, we consider row 1 of $\tilde{S}_L^{\, 1} = 	\begin{bmatrix}
	-1 & 1 & 1 \\
\end{bmatrix}$, $(\vec{r}^{\, 1}_1, \vec{a}^{\, 1}_1) = ([1], [-5])$ and $(\vec{r}^{\, 2}_1, \vec{a}^{\, 2}_1) = ([0], [1])$. Now, row 1 models the relation $ r_1 = \tilde{S}_L^{\, 1}\vec{x}' = -x' + y' + z'$, we observe that $(\vec{r}^{\, 1}_1, \vec{a}^{\, 1}_1)$ decrements $r_1$ by 5, we get the formula $-x' + y' + z' = -x + y + z - 5k_1$. On the other hand we see that $(\vec{r}^{\, 2}_1, \vec{a}^{\, 2}_1)$ resets $r_1$ and increments it by 1, we get the formula $-x' + y' + z' = 1$. Constructing the disjunction of both, we get the transition formula for dimension 1 as:
\begin{equation*}
	 -x' + y' + z' = -x + y + z - 5k_1 \lor -x' + y' + z' = 1
\end{equation*}
If we now proceed to dimension two, we get the relation $r_ 2 = y'$. Both transformer increment $r_2$, yielding the following formula:
\begin{equation*}
	y' = y - 3k_1 + k_2
\end{equation*}
Using these formulas we get the loop summary as seen in Figure \ref{loopSummary}.
\begin{figure}[H]
	\begin{align*}
		\exists k_1, k_2.&\ x' = x\ \land\ y' = y\ \land\ z' = z \\ &\lor ((-x' + y' + z' = 1\ \lor\ -x' + y' + z' = -x + y + z - 5k_2)\ \land\ y' = y - 3k_1 + k_2)\ \\ 
	\end{align*}
	\caption{\\ Summary computed from \qvasr-abstraction $(\tilde{S}_L, \tilde{V}_L)$ for transition formula $L$.}
	\label{loopSummary}
\end{figure}

