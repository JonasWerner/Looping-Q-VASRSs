\newcommand{\stateSpace}{\ensuremath{S_{V, \mu}}}
\begin{comment}
	This chapter is mostly focused on trace abstraction $\rightarrow$  It introduces the reader to the concept of trace abstraction. \\
	- Introduce logic, logical variables, terms, formulas, transition formulas with primed and unprimed variables, programs, program states, loops $\rightarrow$  then program-, error traces, feasible and infeasible counterexamples, CFGs, interpolants. \\ - From intuitive to true definitions. \\
	Here the running example from the introduction gets dissected to illustrate the definitions. \\ 
	Further the problems loops can cause are introduced, followed by a definition of loop summaries $\rightarrow$ introduction reflexive transitive closure of a formula 
	15 pages
\end{comment}

This chapter shall introduce our understanding and notation of logic and formulas, programs, control-flow, and other needed background definitions. Furthermore, we will give an overview of the \traceabstraction \cite{10.1007/978-3-642-03237-0_7} counterexample-guided abstraction refinement scheme used in \ultimate.

\subsection{Logical Background}
To represent programs formally, we make use of first-order logic. This chapter will introduce our definitions and notations used throughout this thesis.

\subsubsection{Notation}
We utilize the standard logical notations: We represent boolean values as $\bot$, meaning \textsl{false}, and $\top$, meaning \textsl{true}. \\ Logical connectives are defined as:
\begin{itemize}
	\item Negation (\textsl{not}) denoted by: $\neg$
	\item Conjunction (\textsl{and}) denoted by: $\land$
	\item Disjunction (\textsl{or}) denoted by: $\lor$
	\item Implication (\textsl{if $\ldots$ then}) denoted by: $\rightarrow$
	\item Biconditional (\textsl{if and only if}) denoted by: $\leftrightarrow$
\end{itemize}
Formulas can be quantified, we define quantifiers as:
\begin{itemize}
	\item Existential quantification (\textsl{there exists}) denoted by: $\exists$
	\item Universal quantification (\textsl{for all}) denoted by: $\forall$
\end{itemize}

\subsubsection{Syntax}
We firstly introduce our first-order logic syntax.
Let $V = (\vocab{Var}, \vocab{Const}, \vocab{Fun}, \vocab{pred})$ be a vocabulary consisting of the countable sets:
\begin{itemize}
	\item $\vocab{Var}$ containing all so called \textsl{variables}
	\item $\vocab{Const}$ containing all so called \textsl{constant symbols}
	\item $\vocab{Fun} $ containing all so called \textsl{function symbols}. Each symbol $f \in \vocab{Fun}$ has a natural number $\geq 1$ called arity of $f$
 	\item $\vocab{Pred}$ containing all so called \textsl{predicate symbols}. Each symbol $p \in \vocab{Pred}$ has a natural number $\geq 0$ called arity of $p$
\end{itemize}
Assume we are given such a vocabulary, we can construct first-order logic terms using the symbols in the vocabulary.
\begin{mydef}[Term] 
	Given a vocabulary $V = (\vocab{Var}, \vocab{Const}, \vocab{Fun}, \vocab{pred})$, we define terms inductively as follows:
	\begin{itemize}
		\item Every $x \in \vocab{Var}$ is a term.
		\item Every $c \in \vocab{Const}$ is a term.
		\item If $t_0, \ldots, t_n$ are terms and $f \in \vocab{Fun}$ being a function symbol with arity $n$, then $f(t_0, \ldots, t_n)$ is a term.
	\end{itemize}
\end{mydef}
Using first-order logic terms, we can introduce first-order logic formulas.
\begin{mydef}[Formula]
	Given vocabulary $V = (\vocab{Var}, \vocab{Const}, \vocab{Fun}, \vocab{pred})$, first-order logic formulas are inductively defined as follows:
	\begin{itemize}
		\item $\bot$ is a formula.
		\item If  $t_0, \ldots, t_n$ are terms, and $p \in \vocab{pred}$ is a predicate symbol with arity $n$, \\ then $p(t_0, \ldots, t_n)$ is a formula.
		\item If $\varphi$ is a formula, then $\neg \varphi$ is a formula.
		\item If $\varphi$ and $\psi$ are formulas, then $\varphi \land \psi$ are formulas.
		\item If $\varphi$ is a formula, and $x \in \vocab{Var}$ then $\exists x. \varphi$ is a formula.
	\end{itemize}
\end{mydef}
To give variables, constants, functions, and predicates concrete values, we can assign them a model.
\begin{mydef}[Model]
	Given vocabulary $V = (\vocab{Var}, \vocab{Const}, \vocab{Fun}, \vocab{pred})$, a model $\mathcal{M} = (D, \interpret)$ is a tuple consisting of a nonempty set $D$, called interpretation domain, and an interpretation function \interpret that assigns constants, functions, and predicates over $D$ to symbols in $V$. $M$ has the following characteristics:
	\begin{itemize}
		\item The domain of \interpret is $\vocab{Const} \cup \vocab{Fun} \cup \vocab{Pred}$
		\item \interpret maps every constant symbol $c \in \vocab{Const}$ to an element in $D$
		\item \interpret maps every function symbol $f \in \vocab{Fun}$, with arity $n$, to a corresponding n-ary function with domain $D^n$ and range $D$
		\item \interpret maps every predicate symbol $p \in \vocab{Pred}$ with arity $n$ to an n-ary relation over the domain $D$
	\end{itemize}
\end{mydef}
Using a model, we can now assign concrete values to variables.
\begin{mydef}[Assignment of Variables]
	Given vocabulary $V = (\vocab{Var}, \vocab{Const}, \vocab{Fun}, \vocab{pred})$, and model $\mathcal{M} = (D, \interpret)$, an assignment of variable $v \in \vocab{Var}$ is a function $\rho: v \rightarrow D$. Mapping each variable a value in domain $D$.
\end{mydef}
Assume $f \in \vocab{Fun}$ is a function defined as $f: X \mapsto Y$ with some domain $X$ and range $Y$. Let $x \in X$ and $y \in Y$, we use $f[x \mapsto y]$  to denote the function that maps all $\bar{x} \in X \backslash \{ x \}$ to $f(\bar{x})$ and $x$ to $y$.

\subsubsection{Semantics}
Assume we are given a vocabulary $V = (\vocab{Var}, \vocab{Const}, \vocab{Fun}, \vocab{pred})$, we know how to assign values using models and variable assignments. The task now is to understand how to interpret them. This section serves to introduce semantics of fist-order logic.
\begin{mydef}[Evaluation of Terms]
	Let $V = (\vocab{Var}, \vocab{Const}, \vocab{Fun}, \vocab{pred})$ be a vocabulary, $\mathcal{M} = (D, \interpret)$ a model, and $\rho$ a variable assignment. The evaluation of terms is a function $\eval{\cdot}$ that is inductively defined as:
	\begin{itemize}
		\item For each $v \in \vocab{Var}$, $\eval{v} = \rho(v)$
		\item For each $c \in \vocab{Const}$, $\eval{c} = \interpret(c)$
		\item If $t_0, \ldots, t_n$ are terms, $f \in \vocab{Fun}$, with f having arity $n$ then \\ $\eval{f(t_0, \cdots, t_n)}$ is $\interpret(f)(\eval{t_0}, \ldots, \eval{t_n})$
	\end{itemize}
\end{mydef}
From the evaluation of terms we can derive the evaluation of formulas, which decides whether a formula is \textsl{true} or \textsl{false}.

\begin{mydef}[Evaluation of Formulas]
		Let $V = (\vocab{Var}, \vocab{Const}, \vocab{Fun}, \vocab{pred})$ be a vocabulary, $\mathcal{M} = (D, \interpret)$ a model, a variable assignment $\rho$, and $\varphi_0, \varphi_1$ being first-order logic formulas over $V$. The evaluation of formulas is a function $\eval{\cdot}$ that is inductively defined as: \\
		\begin{itemize}
			\item {\makebox[3cm]{$\eval{\bot} \hfill$}} \textbf{false}
			\item {\makebox[3cm]{$ \eval{p(t_0, \ldots, t_n)} \hfill$}} 
				$
				\begin{cases}
					\textbf{true}, & \text{for } (\eval{t_0}, \ldots, \eval{t_n}) \in \interpret(p)\\
					\textbf{false}, & \text{otherwise}
				\end{cases}
				$
			\item {\makebox[3cm]{$\eval{\neg \varphi_0} \hfill$}}
				$
				\begin{cases}
					\textbf{true}, & \text{for } \eval{\varphi_0} \text{ \textbf{false}}\\
					\textbf{false}, & \text{for } \eval{\varphi_0} \text{ \textbf{true}}\\
				\end{cases}
				$
			\item {\makebox[3cm]{$\eval{\varphi_0 \land \varphi_1} \hfill$}}
				$
				\begin{cases}
					\textbf{true}, & \text{for } \eval{\varphi_0} \text{ \textbf{true} and } \eval{\varphi_1} \text{ \textbf{true}} \\
					\textbf{false}, & \text{otherwise} \\
				\end{cases}
				$
			\item {\makebox[3cm]{$\eval{\exists v. \varphi_0} \hfill$}}
				$
				\begin{cases}
					\textbf{true}, & \text{if there exists } x \in D \text{ where } \eval{\varphi_0 [v \mapsto x]} \text{ \textbf{true}} \\
					\textbf{false}, & \text{otherwise} \\
				\end{cases}
				$
		\end{itemize}
\end{mydef}
A formula $\varphi$ is called satisfiable if there exists a model $\mathcal{M} = (D, \interpret)$ and a variable assignment $\rho$ such that $\eval{\varphi}$ is true. A formula is valid if there is no model $\mathcal{M} = (D, \interpret)$, such $\eval{\varphi}$ is false.
In the following we will omit the model notation... \jw{todo}
\subsection{Programs}
In this chapter we will introduce our understanding on how to model programs using first-order logic. We will begin with our syntax of programs, then explain program statement semantics.

\subsubsection{Program Syntax}
Assume we are given the example program as seen in figure \ref{code}. We see that the code contains various typed variables such as \texttt{x : int} and instructions over these variables. \\ These instructions use the following context-free grammar $\Sigma$ that is a derived and simplified version of the grammar of the intermediate verification language Boogie\cite{Boogie}.
\setlength{\grammarparsep}{20pt plus 1pt minus 1pt} % increase separation between rules
\setlength{\grammarindent}{12em} % increase separation between LHS/RHS
\begin{figure}[H]
	\input{fig/grammar.tex}
	\caption{Context-free grammar $\Sigma$ detailing program instructions.}
	\label{grmr}
\end{figure}
We call words derived from $\langle Stmt \rangle$ program statements, words derived from $\langle Expr \rangle$ expressions, and $v \in V$ represents a program variable and $c$ represents a constant in a fitting model.
We define programs as follows:

\begin{mydef}[Programs]
	A program is a triple \prg, with $V$ being a set of variables, a function $\mu: V \rightarrow \{ \mathbb{Z}, \mathbb{R}, \mathbb{B} \}$ that maps variables $v \in V$ to a domain, which is either the set of integers, the rational numbers, or boolean values $\mathbb{B} = \{\textbf{true}, \textbf{false}\}$. Furthermore, $st$ is a derived word from $\Sigma$ representing the program instructions.
\end{mydef}
\subsubsection{Program Semantics}
We consider five kinds of program statements in the grammar $\Sigma$: An assumption over variables \texttt{assume}, an assignment to variables \texttt{:=}, a non deterministic assignment \texttt{havoc}, a program loop \texttt{while}, that repeats a statement until its loop guard, the $\langle WildcardExpr \rangle$, no longer holds, and an conditional branching, in form of an \texttt{if else} statement. With the first three: \st{assume $\langle Expr \rangle$ }, \st{v := $\langle Expr \rangle$}, and \st{havoc v}, being atomic statements. Whereas \texttt{while} and \texttt{if else} are a compound of atomic statements.
We regard expressions $\langle Expr \rangle$ as logical formulas. Most program statements change the assignment of variables and with that changes the state a program is in. 
\begin{mydef}[Program State]
	Given a program \prg a program state is a function $\sigma: V \rightarrow \mu(V)$ that assigns each variable $v \in V$ a value in its domain $\mu(v)$. We denote the set of all program states as \stateSpace.
\end{mydef}
We use fist-order logic formulas to detail sets of states.
\begin{mydef}[Sets of Program States]
	Given a first-order logic formula $\varphi$, a set of program states $\{ \varphi \}$ contains all program states $\sigma_i$ for which $\eval{\varphi [V\mapsto \mu_i(V) ]}$ is true.
\end{mydef}
Using program states, we can now set the semantics for the three atomic program statements.
\begin{mydef}[Program Statement Semantics]
		Given a program \prg, we define the semantics of program statements as a binary relation over program states $\sigma_1, \sigma_2$, whereas $\sigma_1$ denotes the program's state before the statement and $\sigma_2$ after. To model time steps, the variables in $\sigma_2$ are replaced by so called primed variables, meaning every variable $v \in Var$ is replaced by $v'$. \\
	\begin{itemize}
		\item The semantics of the \textnormal{\texttt{assumption}} statement: \textnormal{\st{assume $\langle Expr \rangle$}} are defined as the relation: \\
		\begin{equation*}
			\{(\sigma_1, \sigma_2) \in \stateSpace \times \stateSpace\ |\ \eval{\langle Expr \rangle}\ \land\ \bigwedge\limits_{v \in V} v' = v  \text{ is true}\}
		\end{equation*}
		\item The semantics of the \textnormal{\texttt{assignment}} statement: \textnormal{\st{v := $\langle Expr \rangle$}} are defined as the relation: \\
		\begin{equation*}
			 \{(\sigma_1, \sigma_2) \in \stateSpace \times \stateSpace\ |\ \eval{x' = \eval{\langle Expr\rangle}\ \land\ \bigwedge\limits_{v \in V, v \not= x} v' = v 
			} \text{ is true}\}
		\end{equation*}
		\item The semantics of the \textnormal{\texttt{havoc}} statement: \textnormal{\st{havoc v}} are defined as the relation: \\
		\begin{equation*}
			\{(\sigma_1, \sigma_2) \in \stateSpace \times \stateSpace\ |\ \bigwedge\limits_{v 	\in V, v \not= x} v' = v 
			\text{ is true} \}
		\end{equation*}
	\end{itemize}
\end{mydef}


\begin{comment}
	\begin{mydef}[Sets of Program States]
	To represent multiple program states we use first-order logic formulas. Given a first-order logic formula $\varphi$, defined over variables in $V$, we denote $\{\varphi\} = \{s \in \stateSpace | \eval{\varphi} \text{ where } \rho = s\}$
	\end{mydef}
\end{comment}
To model while and if else, we can concatenate these three atomic statements to form sequences of statements.
\begin{mydef}[Concatenation of Program Statements]
	Let \st{$s_1$} and \st{$s_2$} be atomic program statements and $\sigma_1$, $\sigma_2$ be program states, the semantics of the concatenation \st{$s_1;s_2$} are defined as:
	\begin{equation*}
		\{(\sigma_1, \sigma_2) \in \stateSpace \times \stateSpace\ |\ \exists \sigma_3 \in \stateSpace. (\sigma_1, \sigma_3) \in \text{\st{$s_1$}} \land (\sigma_3, \sigma_2) \in \text{\st{$s_2$}}
	\end{equation*}
\end{mydef}

The change from one program state to another is called a \textsl{transition}. To model transitions efficiently, we introduce transition formulas.
\begin{mydef}[Transition Formula]
		Given a program \prg with variable $v \in V$, transitions from program state $\sigma_1$ to state $\sigma_2$ is characterized by the transition formula defined over variables $V$ and $V'$ whereas $V'$ contains all variables found in $V$ but primed. The set $V$ characterizes the variables before the transition, e.g. the variable valuations in $\sigma_1$, in contrast to $V'$ which represents the variable valuations after the transition. A transition between two states is only possible, if and only if the transition formula is satisfiable for the give states.
\end{mydef}
 We specify for each of the atomic program statements the following transition formulas: 
 \begin{center}
\begin{itemize}
	\item \st{assume $\langle Expr \rangle$}: 
	\begin{equation*}
		Expr\ \land \bigwedge\limits_{v \in V} v' = v 
	\end{equation*}
	\item \st{v := $\langle Expr \rangle$}:
	\begin{equation*}
		v' = Expr\ \land \bigwedge\limits_{v \in V, v \not= x} v' = v 
	\end{equation*}
	\item \st{havoc v}: 
	\begin{equation*}
			\bigwedge\limits_{v \in V, v \not= x} v' = v 
	\end{equation*}
\end{itemize} 
 \end{center}
For brevity's sake we will use the notation \st{$\langle Expr \rangle$} for assumptions, and omit $\bigwedge\limits_{v \in V} v' = v$ in assumptions and assignments. \\
With transition formulas we can model state transitions using the strongest postcondition. The strongest postcondition applied on a program state $\sigma$, that satisfies a given first-order logic formula $\varphi$, and a transition formula \trf results in a formula $\psi$ that the follower states after the transition have to satisfy.
\begin{mydef}[Strongest Postcondition]
	Given a first-order logic formula $\varphi$ and transition formula \trf with set of variables $V$, the strongest postcondition $	sp(\varphi, \trf)$ is the formula defined as:
	\begin{equation*}
		sp(\varphi, \trf) = (\exists V. \varphi \land \tf)[V' \mapsto V]
	\end{equation*}
\end{mydef}
\subsection{Program Verification}
This section serves as an introduction to our understanding of program verification. Our goal is to prove whether a program is \textsl{correct} or to find a counterexample to correctness. In the following we define our understanding of safety, model a program's control-flow, and introduce traces.
\subsubsection{Control-Flow Graph}
 Assume we are given a program \prg, the order in which the program's instructions can be executed is called control-flow. We can construct a directed graph that models this control-flow in form of a control-flow graph.
 
 \begin{mydef}[Control-Flow Graph]
 	Given a program \prg, a control-flow graph $G = (Loc, \Pi, \delta, src, tgt, \loc{init})$ is a directed graph consisting of a finite set of program locations $Loc$, a set of transitions $\Pi$, a set of edges $\delta \subseteq Loc \times \Pi \times Loc$ between two locations, labeled with a transition, a function $src: \Pi \rightarrow Loc$ mapping the source of each transition to a location, a function $tgt: \Pi \rightarrow Loc$ mapping the target of transitions to locations, and an initial location $\loc{init}$. 
 \end{mydef}
To illustrate the notion of control-flow graphs, assume we are given program $P$ as seen in Figure \ref{code}, we construct the control-flow graph $G_P$ seen in Figure \ref{cfg:P:Noass}
.\begin{center}
	\begin{minipage}[b]{0.4\linewidth}
		\begin{figure}[H]
			\centering
			\input{fig/lst_ex_p5.tex}
			\caption{Program $P$.}
			\label{codeNoAss}
		\end{figure}
	\end{minipage}
	\hfill
	\begin{minipage}[b]{0.59\linewidth}
		\begin{figure}[H]
			\centering
			\input{fig/fig_ex_p5_cfg.tex}
			\caption{Control-flow graph $G_P$ for program $P$.}
			\label{cfg:P:Noass}
		\end{figure}
	\end{minipage}
\end{center}
For defining correctness of a program, we need to extend the definition of control-flow graphs, by introducing error locations. An error location signifies an unwanted program state. We construct error locations by using the \texttt{assert} statement in program code. An assertion verifies whether a given expression holds, if so, the program continues normally, if not it terminates, returning that an error location has been reached. We extend control-flow graphs to control-flow graphs with error locations.
 \begin{mydef}[Control-Flow Graph with Error Locations]
	Given a program \\ \prg, a control-flow graph with error location \cfg is a control-flow graph extended by a set of error locations $\loc{err}$.
\end{mydef}
For example, when we extend the program $P$ as seen in \ref{codeNoAss} with an \texttt{assert} statement, we get the control-flow graph depicted in Figure \ref{codeWithAss}. We see the error location $\loc{err}$ which is reached by violating the expression \texttt{x == 22}.
\begin{center}
	\begin{minipage}[b]{0.4\linewidth}
		\begin{figure}[H]
			\centering
			\input{fig/lst_ex_p0.tex}
			\caption{Program $P$ with \\ assertion \texttt{x == 22}.}
			\label{codeWithAss}
		\end{figure}
	\end{minipage}
	\hfill
	\begin{minipage}[b]{0.59\linewidth}
		\begin{figure}[H]
			\centering
			\input{fig/fig_ex_p0_cfg.tex}
			\caption{Control-flow graph $G_P$ with error location $\loc{err}$ for program $P$.}
			\label{cfg:P:Ass}
		\end{figure}
	\end{minipage}
\end{center}
For the rest of the thesis, denote control-flow graph with error location just as control-flow graph except stated otherwise.
\subsubsection{Program Correctness}
The control-flow of a program can now be described by so called traces through the control-flow graph.
\begin{mydef}
	Given a program	\prg, its control-flow graph \\ G = \cfg, a trace $\tau = \trf_1, \trf_2, \ldots $ of a program is a finite or infinite sequence of transitions $\trf_1, \trf_2, \ldots$ with $\trf_i \in \Pi$, and $(scr(\trf_i), \trf_i, tgt(\trf_i)) \in \delta$
\end{mydef}
This definition only establishes that traces adhere to the graph structure of the control-flow graph. We need to set which traces are actually feasible.

\jw{todo: reachability, program traces, etc.}


\subsection{Trace Abstraction}