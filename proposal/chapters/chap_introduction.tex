
Analyzing program loops is an important part of multiple software engineering tasks, such as bug detection, test case generation, and optimization. Loop analysis is, however, one of the most challenging aspects of program analysis, especially with complex loops that feature multiple paths and nested loops. Loop analysis has been called the "Archilles heel" of program verification\cite{DBLP:journals/fmsd/KroeningSTTW13} \par
There are three prominent techniques of loop analysis: loop unwinding, loop invariant calculation, and loop summarization\cite{DBLP:journals/fmsd/KroeningSTTW13 , DBLP:conf/cav/SilvermanK19, DBLP:journals/tse/XieCZLLL19}. Loop unwinding deals with a loop by unrolling each loop iteration until a certain number. This technique is quite simple but cannot reason about the program behavior beyond the unwinding bound. \\
Loop invariants are properties that hold before and after each loop iteration, modeling its behaviour. The usefulness of loop invariants is however tied to how strong they are, and finding sufficiently strong invariants "is an art"\cite{DBLP:journals/fmsd/KroeningSTTW13}. A software-model checker, for example, may not terminate if given loop invariants are insufficiently general. \par
Loop summarization on the other hand provides a more accurate and complete view of the loop. A loop summary models the relationship between inputs and outputs as a set of constraints that can be used to replace the loop in a program. Loop summaries are not guaranteed to be precise, meaning they can over- or underapproximate the loop's behavior. Counterexamples found using underapproximative loop summaries are guaranteed to be feasible. But due to the underapproximate nature of the summaries they can miss other feasible counterexample as they model only a subset of the actual loop behavior \cite{DBLP:journals/fmsd/KroeningLW15} Overapproximative loop summaries on the other hand form a superset of the actual loop behavior, resulting in possible spurious counterexamples. The quality of overapproximative loop summaries depends on how much the summary overapproximates the actual loop behavior.\\ \par
Silverman and Kincaid\cite{DBLP:conf/cav/SilvermanK19} proposed an overapproximative loop summarization that \textsl{guarantees} a certain degree of approximation precision.\par 

The proposed technique makes use of vector addition systems which are a prominent class of infinite-state transition systems with decidable reachability \cite{DBLP:conf/rp/HaaseH14}. A vector addition system consists of a finite number of integer-typed variables, when a transition is taken the variables are updated by addition of a constant. Silverman and Kincaid use a variation of vector addition systems that are based on rational-typed variables instead of integers and extend transitions by employing the notion of resets. When a transition is taken in a rational vector addition systems (\qvasr) a variable is either incremented by a constant, reset to 0, or reset and incremented by a constant.
A \qvasr of dimension $d$ is a finite set $V \subseteq \{0, 1\}^d \times \mathbb{Q}^d$ of transformers. Each transformer $(\vec{r}, \vec{a}) \in V$ consists of binary \textsl{reset} vector $\vec{r}$ and rational \textsl{addition} vector $\vec{a}$. Using these transformers, a transitions between two vectors $\vec{v}$ and $\vec{v}$ is defined as: $\vec{v} = \vec{u} * \vec{r} + \vec{a}$, with $*$ being the Hadamard product. Figure \ref{code} depicts a program containing a \texttt{while} loop from lines 4-12 for which we want to compute a loop summary using \qvasr. To do that one has to compute \qvasr for every branch. Starting with the else branch in lines 10 and 11, we extract the transition formula $G: x > 10 \land x' = x + 2 \land y' = y - 3$. It is evident that neither x or y is reset, but incremented by 2 and decremented by 3 respectively. We get reset vector $\vec{r}_G: \begin{pmatrix} 0 \\ 0\end{pmatrix}$ and addition vector $\vec{a}_G: \begin{pmatrix} 2 \\ -3\end{pmatrix}$.  \par
When we consider the if branch in lines 5-8, which has transition formula $H: x' = x + y\ \land\ y' = y + 1 \land z' = x$, we realize that variables $x$ and $z$ are changed not by a constant but by a variable amount. A \qvasr can only model transitions with constant resets and increments, such that we cannot easily compute one for $H$. However, when we transform $H$ by substituting $x$ by $z'$ and $y$ by $y'-1$ we get the constant relation between variables: $-x' + y' + z' = 1$. The variable relation $-x' + y' + z'$ can now be simulated to a \qvasr using a linear simulation. A \textsl{linear simulation} $S$ is a rational matrix simulating variable relations to a \qvasr. Given a \qvasr $V$, we extend the notion of \qvasr transitions to make use of $S$: $S\vec{v} = S\vec{u} * \vec{r} + \vec{a}$ for some $(\vec{r}, \vec{a}) \in V$. For $H$ we compute the linear simulation $S_H = \begin{pmatrix}
	-1 & 1 & 1 \\
	0 & 1 & 0
\end{pmatrix}$, in which the first row represents the relation $-x + y + z$ and the second row, representing just $y$, stems from the conjunct $y' := y + 1$. The tuple $(S, V)$ is called a \qvasr-abstraction. \par
and is not unique. To get the most precise overapproximation of the behavior of a transition formula we need the \textsl{best} \qvasr-abstraction $(\tilde{S}, \tilde{V})$ that simulates the most transitions of the formula. We impose a partial order $\preceq$ on \qvasr-abstractions where $(S, V) \preceq (\tilde{S}, \tilde{V})$ for all other \qvasr-abstractions. $(\tilde{S}, \tilde{V})$ is the least upper bound with regard to $\preceq$ and is computed by iteratively joining abstractions. The best abstraction is then used to compute the summary of a transition formula. \\ Illustrating the notion of \qvasr and \qvasr-abstractions further, we introduce Figure \ref{code} which shows an example program containing a loop from lines 4 to 12, with Figure \ref{vasr} depicting the loop's best \qvasr-abstraction $(S,V)$. $V$ consists of two reset and addition vector pairs representing the two branches created by the \texttt{if else} statement in the loop. Having multiple pairs of reset and addition vectors can lead to a loss in precision. In the example, we see that the conditions of the \texttt{if} and \texttt{else} statements, \texttt{x <= 10} and \texttt{x > 10}, are not modeled in $V$, leading to the inclusion of transitions that would violate these conditions in the actual loop. \\
\begin{minipage}[t]{0.3\linewidth} \centering
	\begin{figure}[H]
		\input{fig/lst_ex_p0.tex}
		\caption{Program $P$ \\ with \texttt{while} loop.}
		\label{code}
	\end{figure}
\end{minipage}
\begin{minipage}[t]{0.35\linewidth} \centering
	\begin{figure}[H]
			\input{fig/matrix_ex_p0.tex}
			\caption{\\ Best \qvasr-abstraction \\ of $P$'s loop.}
			\label{vasr}
	\end{figure}
\end{minipage}
\begin{minipage}[t]{0.3\linewidth} \centering
	\begin{figure}[H]
		\input{fig/qvasrs_ex_p0.tex}
		\caption{\\ \qvasrs of $P$'s loop.}
		\label{vasrs}
	\end{figure}
\end{minipage}
\vspace*{1cm}

To improve precision we introduce $\qvasr$ with states (\qvasrs). Given a \qvasr $V$, a \qvasrs of dimension $d$ is a pair $\mathcal{V} = (P, E)$, with $P$ being a finite set of control states given as predicates and $E \subseteq P \times (\vec{r}, \vec{a}) \times P$ with $(\vec{r}, \vec{a}) \in V$ being a finite set of edges. For all $p \neq q \in P$ we have $p \land q$ unsatisfiable. Now, a \qvasrs can transition between two vectors $\vec{u}$ and $\vec{v}$ if there is an edge $(p, (\vec{r}, \vec{a}), q) \in E$, with $\vec{v} = \vec{r} * \vec{u} + \vec{a}$. \par
Figure \ref{vasrs} details the \qvasrs of $P's$ loop, in which the \texttt{if else} conditions hold. \par
To compute summary of a transition formula one has to calculate it the reachability relation of the transitions's \qvasrs. Haase and Halfon \cite{DBLP:conf/rp/HaaseH14} proposed a polytime procedure that unwinds an integer vector addition system into multiple formulas that, as conjunction, form the reflexive transitive closure. This procedure can be adapted to work with \qvasrs. \\ \par

\textsc{Ultimate}\cite{Zitat02} is a software analysis framework consisting of multiple plugins and libraries for various software verification tasks. \textsc{Ultimate} already features multiple loop summarization techniques, they, however, have problems with nested loops, loop branching, and approximation precision. Problems that can be potentially remedied by the usage of \qvasrs. We plan on implementing a new loop summarization library based on \qvasrs, integrate it into the \texttt{accelerated interpolation} scheme, which computes state assertions for programs utilizing loop summaries, and compare the performance of \qvasrs to other implemented loop summarization techniques. \par
The remainder of this proposal is structured as follows, in section \ref{prob} we formulate our problem statement, followed by an outline of the project's approach in section \ref{app}, and last but not least we present a timetable showing the chronological order of the project in section \ref{sched}.
