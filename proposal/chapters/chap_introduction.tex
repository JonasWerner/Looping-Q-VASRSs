
Analyzing program loops is an important part of multiple software engineering tasks, such as bug detection, test case generation, and optimization. Loop analysis is, however, one of the most challenging aspects of program analysis, especially with complex loops that feature multiple paths and nested loops. Loop analysis has been called the "Archilles heel" of program verification\cite{DBLP:journals/fmsd/KroeningSTTW13}. \par
There are three prominent techniques of loop analysis: loop unwinding, loop invariant calculation, and loop summarization\cite{DBLP:journals/fmsd/KroeningSTTW13 , DBLP:conf/cav/SilvermanK19, DBLP:journals/tse/XieCZLLL19}. Loop unwinding deals with a loop by unrolling each loop iteration until a certain number. This technique is quite simple but cannot reason about the program behavior beyond the unwinding bound. \\
Loop invariants are properties that hold before and after each loop iteration, modeling its behaviour. The usefulness of loop invariants is however tied to how strong they are, and finding sufficiently strong invariants "is an art"\cite{DBLP:journals/fmsd/KroeningSTTW13}. A software-model checker, for example, may not terminate if given loop invariants are insufficiently general. \par
Loop summarization on the other hand provides a more accurate and complete view of the loop. A loop summary models the relationship between inputs and outputs as a set of constraints that can be used to replace the loop in a program. Loop summaries are not guaranteed to be precise, meaning they can over- or underapproximate the loop's behavior. Counterexamples found using underapproximative loop summaries are guaranteed to be feasible. But due to the underapproximate nature of the summaries they can miss other feasible counterexample as they model only a subset of the actual loop behavior \cite{DBLP:journals/fmsd/KroeningLW15} Overapproximative loop summaries on the other hand form a superset of the actual loop behavior, resulting in possible spurious counterexamples. The quality of overapproximative loop summaries depends on how much the summary overapproximates the actual loop behavior.\\ \par
Silverman and Kincaid\cite{DBLP:conf/cav/SilvermanK19} proposed an overapproximative loop summarization that \textsl{guarantees} a certain degree of approximation precision.\par 

The proposed technique makes use of vector addition systems which are a prominent class of infinite-state transition systems with decidable reachability \cite{DBLP:conf/rp/HaaseH14}. A vector addition system consists of a finite number of integer-typed variables, when a transition is taken variables are updated by addition of a constant. Silverman and Kincaid use a variation of vector addition systems that are based on rational-typed variables instead of integers and extend transitions by employing the notion of resets. When a transition is taken in a rational vector addition systems (\qvasr) a variable is either incremented by a constant, reset to 0, or reset and incremented by a constant.
A \qvasr of dimension $d$ is a finite set $V \subseteq \{0, 1\}^d \times \mathbb{Q}^d$ of transformers. Each transformer $(\vec{r}, \vec{a}) \in V$ consists of binary \textsl{reset} vector $\vec{r}$, where 0 indicates a reset, and rational \textsl{addition} vector $\vec{a}$. Using these transformers, a transition between two vectors $\vec{u}$ and $\vec{v}$ is defined as: $\vec{v} = \vec{u} * \vec{r} + \vec{a}$, with $*$ being the Hadamard product. Figure \ref{code} depicts a program containing a \texttt{while} loop from lines 4-12 for which we want to compute a loop summary using \qvasr. To do that one has to compute a \qvasr for every path through the loop. In this example there are two paths, created by the \texttt{if else} statement. Beginning with the \texttt{else} branch in lines 10 and 11, we extract the transition formula $G$:
\begin{equation*}
	G= \ (x > 10 \land x' = x + 2 \land y' = y - 3)
\end{equation*}
 It is evident that neither $x$ or $y$ is reset, but incremented by 2 and decremented by 3 respectively. We get reset vector $\vec{r}_G: \begin{pmatrix} 1 \\ 1\end{pmatrix}$ and addition vector $\vec{a}_G: \begin{pmatrix} 2 \\ -3\end{pmatrix}$.  \par
From the \texttt{if} branch in lines 5-8 we extract the following transition formula.
\begin{equation*}
	H= \ (x \leq 10 \land x' = x + y\ \land\ y' = y + 1 \land z' = x)
\end{equation*} We realize that variables $x$ and $z$ are changed not by a constant but by a variable amount. A \qvasr can only model transitions with constant resets and increments, making it difficult to compute one for $H$. However, when we transform $H$ by substituting $x$ by $z'$ and $y$ by $y'- 1$ we get the constant relation between variables: $-x' + y' + z' = 1$. This relation can be modeled by a \qvasr using a linear simulation. A \textsl{linear simulation} $S$ is a rational matrix projecting variable relations to a \qvasr. Given \qvasr $V$, we extend the notion of transitions to make use of linear simulations: $S\vec{v} = S\vec{u} * \vec{r} + \vec{a}$ for some $(\vec{r}, \vec{a}) \in V$. For $H$ we compute the linear simulation $S_H = \begin{pmatrix}
	-1 & 1 & 1 \\
	0 & 1 & 0
\end{pmatrix}$, in which the first row represents the relation $-x + y + z$ and the second row, stemming from the conjunct $y' = y + 1$, represents just $y$. The tuple $(S, V)$ is called a \textsl{\qvasr-abstraction}. For transition formulas with constant increments, such as $G$, an identity matrix $I$ is used as simulation matrix. \par
The effect on variables by the loop in $P$ can be represented by the disjunction of $G$ and $H$, for whom we have already computed \qvasr-abstractions. These, however, only model the effect on variables in their respective branch of the \texttt{if else} statement. To get the most precise overapproximation of the whole loop's behavior we need the \textsl{best} \qvasr-abstraction $(\tilde{S}, \tilde{V})$ that simulates every branch in the loop.
We impose a partial order $\preceq$ on \qvasr-abstractions $(S_1, V_1)$ and $(S_2, V_2)$, with $(S_1, V_1) \preceq (S_2, V_2)$ if $(S_2, V_2)$ simulates $(S_1, V_1)$. The best abstraction $(\tilde{S}, \tilde{V})$ is the least upper bound with regard to $\preceq$, meaning $(S, V) \preceq (\tilde{S}, \tilde{V})$ for all \qvasr-abstractions $(S, V)$. The abstraction $(\tilde{S}, \tilde{V})$ computed by iteratively \textsl{joining} abstractions. Joining two \qvasr-abstractions results in a single abstraction simulating both. Figure \ref{vasr} shows the best \qvasr-abstraction of $P$'s loop, which is the result of joining $G$'s and $H$'s abstractions. \\

We see in the example that the conditions of the \texttt{if else} statement, \texttt{x <= 10} and \\ \texttt{x > 10}, are not modeled in the \qvasr-abstraction $(S_P, V_P)$, which leads to the inclusion of transitions that would violate these conditions in the actual loop and would therefore not exist. \\

\begin{minipage}[t]{0.3\linewidth} \centering
	\begin{figure}[H]
		\input{fig/lst_ex_p0.tex}
		\caption{Program $P$ \\ with \texttt{while} loop.}
		\label{code}
	\end{figure}
\end{minipage}
\begin{minipage}[t]{0.35\linewidth} \centering
	\begin{figure}[H]
			\input{fig/matrix_ex_p0.tex}
			\caption{\\ Best \qvasr-abstraction \\ of $P$'s loop.}
			\label{vasr}
	\end{figure}
\end{minipage}
\begin{minipage}[t]{0.3\linewidth} \centering
	\begin{figure}[H]
		\input{fig/qvasrs_ex_p0.tex}
		\caption{\\ \qvasrs of $P$'s loop.}
		\label{vasrs}
	\end{figure}
\end{minipage}
\vspace*{1cm}

To exclude such transitions we constrain \qvasr. We only allow transitions that satisfy a set of predicates $P$. Using predicates in $P$ as control states, we can construct a nondeterministic finite automaton that represents all allowed transitions. This automaton is called a \qvasr with states (\qvasrs), where each transition is labeled by a reset, addition vector pair $(\vec{r}, \vec{a})$. The predicates are pairwise unsatisfiable, minimizing the automaton's possible successor state space. A vector $\vec{u}$ can only transition to $\vec{v}$ if there is an edge $(p, (\vec{r}, \vec{a}), q)$, with $\vec{v} = \vec{r} * \vec{u} + \vec{a}$ and $p, q \in P$. \par
Figure \ref{vasrs} shows the \qvasrs of $P$'s loop, it was constructed using $(S_P, V_P)$, seen in Figure \ref{vasr}, and the predicates $x \leq 10$ and $10 < x \land x \leq 20$ as states. We see that there are no transitions that violate the \texttt{if else} conditions. \par
To compute a loop summary, one has to calculate the reachability relation of the \qvasrs. Haase and Halfon \cite{DBLP:conf/rp/HaaseH14} proposed a polytime procedure that unwinds an integer vector addition system into multiple formulas that, as conjunction, form a summary of the system. This procedure can be adapted to work with \qvasrs. \\ \par

\textsc{Ultimate}\cite{Zitat02} is a software analysis framework consisting of multiple plugins and libraries for various software verification tasks. \textsc{Ultimate} already features numerous loop summarization techniques, they, however, have problems with nested loops, loop branching, and approximation precision. Problems that can be potentially solved by the usage of \qvasrs. We plan on implementing a new loop summarization library based on \qvasrs, integrate it into the \texttt{accelerated interpolation} scheme, which computes state assertions for programs utilizing loop summaries, and compare the performance of \qvasrs to other implemented loop summarization techniques. \par
The remainder of this proposal is structured as follows, in section \ref{prob} we formulate our problem statement, followed by an outline of the project's approach in section \ref{app}, and last but not least we present a timetable showing the chronological order of the project in section \ref{sched}.
